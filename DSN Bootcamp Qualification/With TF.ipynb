{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "sample = pd.read_csv(\"SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4990, 14) (3532, 13) (8522, 14)\n"
     ]
    }
   ],
   "source": [
    "#Combine test and train into one file\n",
    "train['source']='train'\n",
    "test['source']='test'\n",
    "data = pd.concat([train, test],ignore_index=True)\n",
    "print (train.shape, test.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Product_Weight'] = data['Product_Weight'].fillna(0)\n",
    "sum(data['Product_Weight'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Supermarket_Size'] = data['Supermarket _Size'].fillna('NaN')\n",
    "sum(data['Supermarket_Size'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Supermarket_Opening_Year'] = 2016 - data['Supermarket_Opening_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Fat_Content</th>\n",
       "      <th>Product_Identifier</th>\n",
       "      <th>Product_Price</th>\n",
       "      <th>Product_Shelf_Visibility</th>\n",
       "      <th>Product_Supermarket_Identifier</th>\n",
       "      <th>Product_Supermarket_Sales</th>\n",
       "      <th>Product_Type</th>\n",
       "      <th>Product_Weight</th>\n",
       "      <th>Supermarket _Size</th>\n",
       "      <th>Supermarket_Identifier</th>\n",
       "      <th>Supermarket_Location_Type</th>\n",
       "      <th>Supermarket_Opening_Year</th>\n",
       "      <th>Supermarket_Type</th>\n",
       "      <th>source</th>\n",
       "      <th>Supermarket_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>DRA12</td>\n",
       "      <td>357.54</td>\n",
       "      <td>0.068535</td>\n",
       "      <td>DRA12_CHUKWUDI010</td>\n",
       "      <td>709.08</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>11.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHUKWUDI010</td>\n",
       "      <td>Cluster 3</td>\n",
       "      <td>11</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>DRA12</td>\n",
       "      <td>355.79</td>\n",
       "      <td>0.040912</td>\n",
       "      <td>DRA12_CHUKWUDI013</td>\n",
       "      <td>6381.69</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>11.6</td>\n",
       "      <td>High</td>\n",
       "      <td>CHUKWUDI013</td>\n",
       "      <td>Cluster 3</td>\n",
       "      <td>22</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>train</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>DRA12</td>\n",
       "      <td>350.79</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>DRA12_CHUKWUDI017</td>\n",
       "      <td>6381.69</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>11.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHUKWUDI017</td>\n",
       "      <td>Cluster 2</td>\n",
       "      <td>2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>DRA12</td>\n",
       "      <td>355.04</td>\n",
       "      <td>0.041113</td>\n",
       "      <td>DRA12_CHUKWUDI018</td>\n",
       "      <td>2127.23</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>11.6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>CHUKWUDI018</td>\n",
       "      <td>Cluster 3</td>\n",
       "      <td>0</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>train</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultra Low fat</td>\n",
       "      <td>DRA12</td>\n",
       "      <td>354.79</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>DRA12_CHUKWUDI035</td>\n",
       "      <td>2481.77</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>11.6</td>\n",
       "      <td>Small</td>\n",
       "      <td>CHUKWUDI035</td>\n",
       "      <td>Cluster 2</td>\n",
       "      <td>5</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>train</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product_Fat_Content Product_Identifier  Product_Price  \\\n",
       "0             Low Fat              DRA12         357.54   \n",
       "1             Low Fat              DRA12         355.79   \n",
       "2             Low Fat              DRA12         350.79   \n",
       "3             Low Fat              DRA12         355.04   \n",
       "4       Ultra Low fat              DRA12         354.79   \n",
       "\n",
       "   Product_Shelf_Visibility Product_Supermarket_Identifier  \\\n",
       "0                  0.068535              DRA12_CHUKWUDI010   \n",
       "1                  0.040912              DRA12_CHUKWUDI013   \n",
       "2                  0.041178              DRA12_CHUKWUDI017   \n",
       "3                  0.041113              DRA12_CHUKWUDI018   \n",
       "4                  0.000000              DRA12_CHUKWUDI035   \n",
       "\n",
       "   Product_Supermarket_Sales Product_Type  Product_Weight Supermarket _Size  \\\n",
       "0                     709.08  Soft Drinks            11.6               NaN   \n",
       "1                    6381.69  Soft Drinks            11.6              High   \n",
       "2                    6381.69  Soft Drinks            11.6               NaN   \n",
       "3                    2127.23  Soft Drinks            11.6            Medium   \n",
       "4                    2481.77  Soft Drinks            11.6             Small   \n",
       "\n",
       "  Supermarket_Identifier Supermarket_Location_Type  Supermarket_Opening_Year  \\\n",
       "0            CHUKWUDI010                 Cluster 3                        11   \n",
       "1            CHUKWUDI013                 Cluster 3                        22   \n",
       "2            CHUKWUDI017                 Cluster 2                         2   \n",
       "3            CHUKWUDI018                 Cluster 3                         0   \n",
       "4            CHUKWUDI035                 Cluster 2                         5   \n",
       "\n",
       "    Supermarket_Type source Supermarket_Size  \n",
       "0      Grocery Store  train              NaN  \n",
       "1  Supermarket Type1  train             High  \n",
       "2  Supermarket Type1  train              NaN  \n",
       "3  Supermarket Type2  train           Medium  \n",
       "4  Supermarket Type1  train            Small  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Product_Price','Product_Shelf_Visibility','Product_Weight','Supermarket_Opening_Year']\n",
    "data[cols] = data[cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Product_Identifier'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data['Supermarket_Opening_Year'].hist(bins=20)\n",
    "#age_buckets = tf.feature_column.bucketized_column(age, boundaries=[0,5,10,15,20,25,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the columns which have been converted to different types:\n",
    "data.drop(['Product_Supermarket_Identifier','Supermarket _Size'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide into test and train:\n",
    "train = data.loc[data['source']==\"train\"]\n",
    "test = data.loc[data['source']==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mo.yosiwealth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\mo.yosiwealth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test.drop(['Product_Supermarket_Sales','source'],axis=1,inplace=True)\n",
    "train.drop(['source'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Product_Supermarket_Sales']\n",
    "X = train.drop(['Product_Supermarket_Sales'],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3493 entries, 3100 to 2732\n",
      "Data columns (total 11 columns):\n",
      "Product_Fat_Content          3493 non-null object\n",
      "Product_Identifier           3493 non-null object\n",
      "Product_Price                3493 non-null float64\n",
      "Product_Shelf_Visibility     3493 non-null float64\n",
      "Product_Type                 3493 non-null object\n",
      "Product_Weight               3493 non-null float64\n",
      "Supermarket_Identifier       3493 non-null object\n",
      "Supermarket_Location_Type    3493 non-null object\n",
      "Supermarket_Opening_Year     3493 non-null float64\n",
      "Supermarket_Type             3493 non-null object\n",
      "Supermarket_Size             3493 non-null object\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 327.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continuous feature_columns for the continuous values using numeric_column\n",
    "\n",
    "price = tf.feature_column.numeric_column('Product_Price')\n",
    "visibility = tf.feature_column.numeric_column('Product_Shelf_Visibility')\n",
    "weight = tf.feature_column.numeric_column('Product_Weight')\n",
    "age = tf.feature_column.numeric_column('Supermarket_Opening_Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.feature_columns for the categorical values. Using vocabulary lists or just use hash buckets.\n",
    "\n",
    "assigned_group_FC = tf.feature_column.categorical_column_with_hash_bucket('Product_Fat_Content', hash_bucket_size=10)\n",
    "assigned_group_PI = tf.feature_column.categorical_column_with_hash_bucket('Product_Identifier', hash_bucket_size=10)\n",
    "assigned_group_PT = tf.feature_column.categorical_column_with_hash_bucket('Product_Type', hash_bucket_size=10)\n",
    "assigned_group_SS = tf.feature_column.categorical_column_with_hash_bucket('Supermarket_Size', hash_bucket_size=10)\n",
    "assigned_group_SI = tf.feature_column.categorical_column_with_hash_bucket('Supermarket_Identifier', hash_bucket_size=10)\n",
    "assigned_group_LT = tf.feature_column.categorical_column_with_hash_bucket('Supermarket_Location_Type', hash_bucket_size=10)\n",
    "assigned_group_ST = tf.feature_column.categorical_column_with_hash_bucket('Supermarket_Type', hash_bucket_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedded_group_FC = tf.feature_column.embedding_column(assigned_group_FC, dimension=3)\n",
    "embedded_group_PI = tf.feature_column.embedding_column(assigned_group_PI, dimension=16)\n",
    "embedded_group_PT = tf.feature_column.embedding_column(assigned_group_PT, dimension=16)\n",
    "embedded_group_SS = tf.feature_column.embedding_column(assigned_group_SS, dimension=3)\n",
    "embedded_group_SI = tf.feature_column.embedding_column(assigned_group_SI, dimension=10)\n",
    "embedded_group_LT = tf.feature_column.embedding_column(assigned_group_LT, dimension=3)\n",
    "embedded_group_ST = tf.feature_column.embedding_column(assigned_group_ST, dimension=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = [price, visibility, weight, age,embedded_group_SS, #embedded_group_SI, , embedded_group_FC,\n",
    "              embedded_group_ST] #, embedded_group_PIembedded_group_LT, embedded_group_PT, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size is up to you. But do make sure to shuffle!\n",
    "\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\MOB005~1.YOS\\AppData\\Local\\Temp\\tmpihrykxhp\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\MOB005~1.YOS\\\\AppData\\\\Local\\\\Temp\\\\tmpihrykxhp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000024509A6DE80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create model with tf.estimator\n",
    "# Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create \n",
    "# embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)\n",
    "\n",
    "\n",
    "model = tf.estimator.DNNRegressor(hidden_units=[14,12,10,8,10,12,14],feature_columns=feat_cols)\n",
    "\n",
    "#model = tf.estimator.LinearRegressor(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\MOB005~1.YOS\\AppData\\Local\\Temp\\tmpihrykxhp\\model.ckpt.\n",
      "INFO:tensorflow:loss = 538558400.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 94.9383\n",
      "INFO:tensorflow:loss = 107471650.0, step = 101 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.605\n",
      "INFO:tensorflow:loss = 87772824.0, step = 201 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.049\n",
      "INFO:tensorflow:loss = 100209970.0, step = 301 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.823\n",
      "INFO:tensorflow:loss = 115824920.0, step = 401 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.968\n",
      "INFO:tensorflow:loss = 177342820.0, step = 501 (0.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.414\n",
      "INFO:tensorflow:loss = 228590800.0, step = 601 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.673\n",
      "INFO:tensorflow:loss = 133910680.0, step = 701 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.103\n",
      "INFO:tensorflow:loss = 35154292.0, step = 801 (0.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.854\n",
      "INFO:tensorflow:loss = 80255230.0, step = 901 (0.675 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\MOB005~1.YOS\\AppData\\Local\\Temp\\tmpihrykxhp\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 53656516.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x24509a6dd30>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your model on the data, for at least 5000 steps.\n",
    "\n",
    "model.train(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MOB005~1.YOS\\AppData\\Local\\Temp\\tmpihrykxhp\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False.\n",
    "\n",
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=10,num_epochs=1,shuffle=False)\n",
    "\n",
    "\n",
    "# Use model.predict() and pass in your input function. This will produce a generator of predictions, \n",
    "# which you can then transform into a list, with list()\n",
    "\n",
    "pred_gen = model.predict(predict_input_func)\n",
    "\n",
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3032.929315890657"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MOB005~1.YOS\\AppData\\Local\\Temp\\tmpu3q9qnqr\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predict_new_data_func = tf.estimator.inputs.pandas_input_fn(x=test,batch_size=10,num_epochs=1,shuffle=False)\n",
    "\n",
    "pred = model.predict(predict_new_data_func)\n",
    "\n",
    "new_data_predictions = list(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_preds = []\n",
    "for pred in new_data_predictions:\n",
    "    new_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Product_Supermarket_Identifier':sample['Product_Supermarket_Identifier'],\n",
    "                                  'Product_Supermarket_Sales': new_preds},\n",
    "                                 columns=['Product_Supermarket_Identifier','Product_Supermarket_Sales'])\n",
    "\n",
    "#to csv\n",
    "submission.to_csv(\"I'm tired.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
